{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1aJQprbnGrt"
      },
      "source": [
        "# **Ethereum Smart Contracts Security Analysis**\n",
        "\n",
        "In this notebook we are going to analyze the state of the abilities of **LLMs** in the context of code generation, particularly for the generation of smart contracts in Solidity, in the Ethereum blockchain.\n",
        "\n",
        "---\n",
        "\n",
        "(*At this moment we are using a dataset and we are no more genrating the prompt ourself, but there's also the old code for prompt generation starting from a dataset containing smart contracts in solidity*)\n",
        "\n",
        "**Huggingface Dataset**: *https://huggingface.co/datasets/braindao/Solidity-Dataset*\n",
        "\n",
        "The steps will be the following:\n",
        "\n",
        "1.   *Import contracts and turn them into prompt* (**OPTIONAL**)\n",
        "\n",
        "1.   Import dataset containing the prompts for the generation\n",
        "\n",
        "2.   Setup OpenAI with API key\n",
        "\n",
        "3.   Setup a text to give as input to the LLM coder containing instructions for the generation\n",
        "\n",
        "4.   **Generate smart contracts**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGdzOt3oSWZV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#UNCOMMENT FIRST THREE LINES IF YOU ARE USING CONTRACT DATASET FOR PROMPT GENERATION\n",
        "\n",
        "#!unzip /content/drive/MyDrive/Ethereum_smart_contract_datast\n",
        "\n",
        "#import shutil\n",
        "#shutil.rmtree('/content/__MACOSX')\n",
        "#shutil.rmtree('/content/Ethereum_smart_contract_datast')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-0ifPZMsR1t"
      },
      "source": [
        "**Setup OpenAI with his API key**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F61ZV8_RRUdq"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key = \"YOUR_API_KEY\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWrdMnUurq9n"
      },
      "source": [
        "## **Contract collection**\n",
        "\n",
        "The following cell is used if we are going to generate the prompts ourself.\n",
        "To do so we load a dataset taken from Github containing a huge amount of smart contracts written for Ethereum in Solidity. We collect a fixed number of contracts to save in local in order to pass them to the prompt generator.\n",
        "\n",
        "**YOU CAN SKIP IT IF YOU ARE USING A PROMPT DATASET**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2FoS7HxBYDR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "contract_codes = []\n",
        "#The dataset is on my Google Drive\n",
        "source_directory = '/content/Ethereum_smart_contract_datast/contract_dataset_github/'\n",
        "codes_collected = 0\n",
        "codes_needed = 500 #To increase the dataset size\n",
        "\n",
        "for root, dirs, files in os.walk(source_directory):\n",
        "    for file in files:\n",
        "        if file.endswith('.sol'):\n",
        "            file_path = os.path.join(root, file)\n",
        "            with open(file_path, 'r') as file:\n",
        "                contract_codes.append(file.read()) #Add the contract code to the array codes_collected\n",
        "                codes_collected += 1\n",
        "                if codes_collected >= codes_needed:\n",
        "                    break\n",
        "\n",
        "    #Stop we you reached the requested number of contracts\n",
        "    if codes_collected >= codes_needed:\n",
        "        break\n",
        "\n",
        "#print(f\"Contracts collected: {len(contract_codes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5QAOzKVB9NW"
      },
      "outputs": [],
      "source": [
        "#IF YOU WANT TO SEE ONE OF THE CONTRACTS COLLECTED\n",
        "index_to_print = 300\n",
        "\n",
        "if 0 <= index_to_print < len(contract_codes):\n",
        "    print(f\"Contract code {index_to_print + 1}:\")\n",
        "    print(contract_codes[index_to_print])\n",
        "else:\n",
        "    print(\"Invalid index\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_YqD6r3hT8c"
      },
      "source": [
        "## **PROMPT GENERATOR**\n",
        "\n",
        "In this section we proceed to generate the prompts for the LLMs.\n",
        "\n",
        "**YOU CAN SKIP IT IF YOU ARE USING A PROMPT DATASET**\n",
        "\n",
        "To do so we defined two different instructions, which gives different level of deepness to the contract generated. **At this moment** the preferred one is **instructions1**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOEG8skomDDp"
      },
      "outputs": [],
      "source": [
        "instructions1 = \"\"\"\n",
        "Generate a prompt for an AI model for creating a contract starting from the smart contract code the user gives you.\n",
        "Underline that it should be in solidity\n",
        "The prompt should be a description of the contract, stating the purpose of it and its rules.\n",
        "If I give the prompt to another AI model it should generate pretty much the same contract.\n",
        "Specify the rules, the purpose and the general description of the code.\n",
        "\"\"\"\n",
        "\n",
        "instructions2 = \"\"\"\n",
        "Generate a prompt for creating a contract starting from the smart contract code the user gives you.\n",
        "Underline that it should be in solidity\n",
        "The prompt should be a description of the contract, stating the purpose of it and its rules.\n",
        "If I give the prompt to another AI model it should generate pretty much the same contract.\n",
        "It should be a simple description\n",
        "Not possible to modify or add anything with respect to the given prompt\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6so53dQxW9N"
      },
      "source": [
        "We give to the generator two parameters:\n",
        "\n",
        "\n",
        "*   The instructions for the generation\n",
        "*   The smart contract that should be turned into prompt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXLX0LKMc3th"
      },
      "outputs": [],
      "source": [
        "def prompt_generatorv1(smartcontract, generator_instructions):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-3.5-turbo\",\n",
        "        messages = [\n",
        "          {\"role\": \"system\", \"content\": generator_instructions},\n",
        "          {\"role\": \"user\", \"content\": smartcontract},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    generated_prompt = response.choices[0].message.content.strip()\n",
        "\n",
        "    return generated_prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYAMcx8MyAQX"
      },
      "source": [
        "**GENERATE 500 PROMPTS SELECTING A RANDOM CONTRACT AND TURNING IT INTO PROMPT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WedDBoeWD5_4"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "prompts = []\n",
        "how_many_prompts = 500\n",
        "\n",
        "for _ in range(how_many_prompts):\n",
        "    #Random contract selection\n",
        "    contract_index = random.randint(0, len(contract_codes) - 1)\n",
        "    selected_contract = contract_codes[contract_index]\n",
        "\n",
        "    prompts.append(prompt_generatorv1(selected_contract, instructions1))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEwkeyDPyH_1"
      },
      "source": [
        "**CELL USED TO PRINT A SELECTED PROMPT JUST TO CHECK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce5I3Zp0F2-h"
      },
      "outputs": [],
      "source": [
        "index_to_print = 14\n",
        "\n",
        "if 0 <= index_to_print < len(prompts):\n",
        "    print(f\"My generated prompt {index_to_print + 1}:\")\n",
        "    print(prompts[index_to_print])\n",
        "else:\n",
        "    print(\"Invalid index\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0Q71yuMYlh"
      },
      "source": [
        "**PROMPT DATASET EXPORT AS A CSV FILE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKq7DK-7MJ0m"
      },
      "outputs": [],
      "source": [
        "data = {\"Prompt\": prompts}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "#Exporting dataset\n",
        "csv_file_path = \"/content/test_prompts_dataset.csv\"  #UNDER CONTRUCTION\n",
        "df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"DATASET SAVED IN {csv_file_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZFJ156URBBR"
      },
      "source": [
        "##**DATASET LOADING FROM HUGGINGFACE**\n",
        "\n",
        "In this section we load the dataset from HuggingFace, the link is available at the beginning of this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYydE_1GZL_U",
        "outputId": "e119c800-af9d-43c2-b563-376fa94c0c07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from IPython.display import display\n",
        "\n",
        "prompt_dataset = pd.read_parquet(\"hf://datasets/braindao/Solidity-Dataset/SolidityP.parquet\")\n",
        "#display(prompt_dataset[['average']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNOL1MC0ogG"
      },
      "source": [
        "**CELL TO CHECK THE CONTENT OF THE DATASET, WE ARE USING COLUMN AVERAGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raMRN3Edvn5A",
        "outputId": "2547ba92-0190-41fc-a232-97d740c62fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create a smart contract that follows the ERC20 token standard, allowing for token transfers, approvals, and burns. Use the SafeMath library for mathematical operations. Ensure that the contract tracks balances, allowances, and total supply accurately. Implement a constructor for initializing the contract name, symbol, and decimal places. Include functions for transferring tokens, approving spenders, and burning tokens. Focus on building a basic, functional contract that follows the ERC20 standard.\n"
          ]
        }
      ],
      "source": [
        "sample_row = prompt_dataset.sample(n=1).iloc[0]\n",
        "print(sample_row['average'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htrKHdXZ2fsz"
      },
      "source": [
        "I save the first 250 prompts to use for the generation, in order to generate the same 250 contracts with both models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fTMt9nk02du"
      },
      "outputs": [],
      "source": [
        "prompts_to_generate = prompt_dataset['average'][:250].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JybNJMXltD5N"
      },
      "source": [
        "## **CODE GENERATION WITH GPT-4**\n",
        "\n",
        "In this section we proceed to actually generate the code for the smart contracts, using GPT4 model. To do so we define the instructions to give to the coder and we decide how many contracts we want to generate, in our case we are going to generate 500 smart contracts\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LmOrQ4qCOZLN"
      },
      "outputs": [],
      "source": [
        "#CODER INSTRUCTIONS\n",
        "\n",
        "coder = \"\"\"\n",
        "You will generate a deployable smart contract code in solidity, based on the prompt I give you.\n",
        "Use Solidity version ^0.8.0\n",
        "\n",
        "The file should contain only solidity code, no comments or \"```sol\".\n",
        "\n",
        "I should be able to copy your response and paste it in a sol file to deploy.\n",
        "Do not use Import statement, only code, if there's any import, replace it with code for the actual imported contract.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibKDDX2oxC3J"
      },
      "outputs": [],
      "source": [
        "#FOLDER FOR SOLIDITY CONTRACTS\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "output_dir = 'gpt_contracts/'\n",
        "\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDIfE-be6BA3"
      },
      "source": [
        "During the manual checking we have seen that the code privided by chatgpt was not always ONLY CODE, but contained additional info or rows that we didn't want, so we created a function that removes everything above the two possible first lines, licence and pragma, and also everything after the last '}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soNLgqHx5x9K"
      },
      "outputs": [],
      "source": [
        "def sanitize_code(code):\n",
        "    #REMOVE EVERYTHING ABOVE // SPDX\n",
        "    spdx_index = code.find('// SPDX')\n",
        "    if spdx_index != -1:\n",
        "        code = code[spdx_index:]\n",
        "    else:\n",
        "        #IF THERE'S NO // SPDX, REMOVE EVERYTHING ABOVE pragma\n",
        "        pragma_index = code.find('pragma')\n",
        "        if pragma_index != -1:\n",
        "            code = code[pragma_index:]\n",
        "\n",
        "    #REMOVE EVERITHING AFTER LAST \"}\"\n",
        "    last_brace_index = code.rfind('}')\n",
        "    if last_brace_index != -1:\n",
        "        code = code[:last_brace_index + 1]\n",
        "\n",
        "    return code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-6npsZR01TM"
      },
      "source": [
        "**CODE GENERATOR PARAMETERS**\n",
        "\n",
        "*   **Coder instructions** defined above\n",
        "*   **Prompt** used for the generation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTUk8VCINljF"
      },
      "outputs": [],
      "source": [
        "def code_generator(prompt, coder_instructions):\n",
        "    response = client.chat.completions.create(\n",
        "        model = \"gpt-4\",\n",
        "        messages = [\n",
        "          {\"role\": \"system\", \"content\": coder_instructions},\n",
        "          {\"role\": \"user\", \"content\": prompt},\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    generated_contract = response.choices[0].message.content.strip()\n",
        "\n",
        "    return generated_contract\n",
        "\n",
        "generated_data = []\n",
        "\n",
        "contracts_to_generate = 250 #SELECT NUMBER OF CONTRACTS NEEDED\n",
        "for i in range(contracts_to_generate):\n",
        "    gpt_contract = sanitize_code(code_generator(prompts_to_generate[i], coder))\n",
        "    prompt_used_gpt = prompts_to_generate[i]\n",
        "    file_name_gpt = f'contract_{i + 1}.sol'\n",
        "\n",
        "    with open(f'/content/gpt_contracts/contract_{i + 1}.sol', 'w') as file:\n",
        "        file.write(sanitize_code(gpt_contract))\n",
        "\n",
        "    generated_data.append([prompt_used_gpt, gpt_contract, file_name_gpt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfc_PZ986ASR"
      },
      "source": [
        "**GENERATE CSV FILE WITH DATA GENERATED**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quo__OHp6FiD"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(generated_data, columns=['prompt_gpt', 'gpt_contract', 'file_name_gpt'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buN4PVx51ZCL"
      },
      "source": [
        "**EXPORT THE FOLDER OF GENERATED CONTRACTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SoOT4J72QBPT",
        "outputId": "5dd8ca2a-bcf2-4e31-d321-18d7e3059419"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_49a0515e-6944-4311-bf58-91e5a58491a3\", \"gpt_contracts.zip\", 203771)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The contracts have been saved and zipped successfully.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive('/content/gpt_contracts', 'zip', '/content/gpt_contracts')\n",
        "files.download('gpt_contracts.zip')\n",
        "\n",
        "\n",
        "print(\"The contracts have been saved and zipped successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_vj55Y5BQrJE",
        "outputId": "90154c0d-d281-4e08-995f-151b03f92acd"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_caa7bddd-344a-4870-b949-047ccfce5bba\", \"gpt.csv\", 5848)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.to_csv('/content/gpt.csv', index=False)\n",
        "files.download('/content/gpt.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpLFO4jJLXyl"
      },
      "source": [
        "## **CODE GENERATION WITH DEEPSEEK-CODER**\n",
        "\n",
        "In this section we proceed to actually generate the code for the smart contracts, using DeepSeek-Coder model. To do so we define the instructions to give to the coder and we decide how many contracts we want to generate, in our case we are going to generate 500 smart contracts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPoweCb0UlGs"
      },
      "outputs": [],
      "source": [
        "#Remove the opening \"```solidity\" and closing \"```\" delimiters\n",
        "\n",
        "def remove_code_delimiters(generated_code):\n",
        "    #Split into lines\n",
        "    lines = generated_code.split('\\n')\n",
        "\n",
        "    #Remove the opening delimiter if it's in the first line\n",
        "    if lines[0].strip() == \"```solidity\":\n",
        "        lines = lines[1:]\n",
        "\n",
        "    #Remove the opening delimiter if it's in the first line\n",
        "    if lines[0].strip() == \"```sol\":\n",
        "        lines = lines[1:]\n",
        "\n",
        "    #Remove the closing delimiter if it's in the last line\n",
        "    if lines[-1].strip() == \"```\":\n",
        "        lines = lines[:-1]\n",
        "\n",
        "    #Join the lines back together\n",
        "    cleaned_code = '\\n'.join(lines)\n",
        "    return cleaned_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYr15x8aw0J2"
      },
      "outputs": [],
      "source": [
        "#FOLDER FOR SOLIDITY CONTRACTS\n",
        "import os\n",
        "\n",
        "output_dir = 'deepseek_contracts/'\n",
        "\n",
        "if os.path.exists(output_dir):\n",
        "    shutil.rmtree(output_dir)\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DX9LUXWPOmv_"
      },
      "outputs": [],
      "source": [
        "deepseek_api_endpoint = \"https://api.deepseek.com\"\n",
        "deepseek_api_key = \"YOUR__API__KEY__HERE\"\n",
        "\n",
        "deepseek_client = OpenAI(api_key=deepseek_api_key, base_url=deepseek_api_endpoint)\n",
        "\n",
        "deepseek_coder_instructions = \"\"\" You will generate a deployable smart contract code in solidity, based on the prompt I give you.\n",
        "                                  Use Solidity version ^0.8.0\n",
        "\n",
        "                                  The contract should be made only in Solidity and it must be ready to deploy\n",
        "                                  only code , do not put \"```solidity\" at the beginning of the response neither ``` at the end.\n",
        "                                  I want a fully deployable file with only code.\n",
        "\n",
        "                                  Do not use Import statement, only code, if there's any import, replace it with code for the actual imported contract.\n",
        "\n",
        "                                  \"\"\"\n",
        "\n",
        "def code_generator_deepseek(prompt, coder_instructions):\n",
        "      response = deepseek_client.chat.completions.create(\n",
        "          model=\"deepseek-coder\",\n",
        "          messages=[\n",
        "              {\"role\": \"system\", \"content\": coder_instructions},\n",
        "              {\"role\": \"user\", \"content\": prompt},\n",
        "          ],\n",
        "          stream=False\n",
        "      )\n",
        "\n",
        "      generated_contract = remove_code_delimiters(response.choices[0].message.content)\n",
        "\n",
        "      return generated_contract\n",
        "\n",
        "deepseek_data = []\n",
        "\n",
        "contracts_to_generate = 250 #SELECT NUMBER OF CONTRACTS NEEDED\n",
        "for i in range(contracts_to_generate):\n",
        "      ds_contract = remove_code_delimiters(code_generator_deepseek(prompts_to_generate[i], deepseek_coder_instructions))\n",
        "      prompt_used_ds = prompts_to_generate[i]\n",
        "      file_name_ds = f'contract_{i + 1}.sol'\n",
        "\n",
        "      with open(f'/content/deepseek_contracts/contract_{i + 1}.sol', 'w') as file:\n",
        "        file.write(ds_contract)\n",
        "\n",
        "      deepseek_data.append([prompt_used_ds, ds_contract, file_name_ds])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUYb1Vf_7SDs"
      },
      "source": [
        "**ADD THE CONTRACT GENERATED BY DEEPSEEK TO THE CSV**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_rsFpnQ7Q8Q"
      },
      "outputs": [],
      "source": [
        "df_deepseek = pd.DataFrame(deepseek_data, columns=['deepseek_prompt', 'deepseek_contract', 'deepseek_file_name'])\n",
        "\n",
        "df_deepseek.to_csv('/content/deepseek.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pwdHcGguwY6Z",
        "outputId": "ccb082ee-a7f1-449e-b385-40e39a4fd9a4"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_4817bef4-0919-4683-8b17-e0246f9664b8\", \"deepseek_contracts.zip\", 222726)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_c7a948ce-7524-4ccf-b74c-804ae1d76b4c\", \"deepseek.csv\", 861569)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The contracts have been saved and zipped successfully.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "shutil.make_archive('/content/deepseek_contracts', 'zip', '/content/deepseek_contracts')\n",
        "files.download('deepseek_contracts.zip')\n",
        "files.download('/content/deepseek.csv')\n",
        "\n",
        "\n",
        "print(\"The contracts have been saved and zipped successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwwH92E_93Ww"
      },
      "source": [
        "## COMBINED CSV DOWNLOAD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF5EgCj_yPwD",
        "outputId": "2d1f9812-8db4-4731-8dea-c93f0b6b6807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged CSV file has been written to /content/gpt_contracts/generated_contracts.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the two CSV files\n",
        "gpt_df = pd.read_csv('/content/gpt.csv')\n",
        "deepseek_df = pd.read_csv('/content/deepseek.csv')\n",
        "\n",
        "# Merge the two dataframes on the specified columns\n",
        "merged_df = pd.merge(gpt_df, deepseek_df, left_on='file_name', right_on='file_name_deepseek')\n",
        "\n",
        "# Save the merged dataframe to a new CSV file\n",
        "merged_csv_path = '/content/generated_contracts.csv'\n",
        "merged_df.to_csv(merged_csv_path, index=False)\n",
        "\n",
        "print(f\"Merged CSV file has been written to {merged_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kn26T64-MCS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "lWrdMnUurq9n",
        "8_YqD6r3hT8c",
        "eZFJ156URBBR"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
